---
layout: post
title: "Selenium的使用及使用场景思路"
date: 2025-11-15
img: ![Selenium.jpg](..%2Fassets%2Fimg%2FSelenium.jpg)
---

Selenium是一个浏览器的自动化工具，可以用来爬虫
但本质是浏览器自动化驱动，主要作用是模拟真人操作浏览器，渲染出完整网页，因此能解决静态爬虫爬不到动态数据的问题
一般来说，网页上显示什么，Selenium就能爬取什么
爬虫流程就是使用Selenium，操控目标浏览器，然后登录
登录窗口一般都是在iframe里边的，所以需要先进去iframe，（登录表单常嵌在 iframe 中
再使用Selenium自动输入账号密码，碰到验证码，可以把验证码截图下来，通过打码平台来进行解决
登录成功后就可以在网页里进行切换页面，获取数据的基本操作（无需分析Ajax接口，js逆向

虽然Selenium能够解决大部分的网页爬取，但获取数据的效率就过于低下了。这时候能加载动态渲染页面的优势反而在追求效率的爬虫下就不够看了，
因为要渲染页面，执行js等操作，会使用较多的系统资源，而且在浏览器中的每个操作都会有加载延迟，单线程下的效率就很低，根本不适合大规模、高并发下的爬虫。
对于一些需要登录获取的数据，可以结合Selenium先登录，拿去到cookie后再返回到使用requests去发送请求获取数据。必要时也可以使用Selenium搭配账号池去定时登录获取cookie
去搭建cookie池，配合Redis-Scrapy完成日均十万的数据爬取




